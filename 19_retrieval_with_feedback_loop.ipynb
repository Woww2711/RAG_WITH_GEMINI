{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf493bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "path = \"data/Understanding_Climate_Change.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03dab458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_t_with_space(list_of_documents):\n",
    "    for doc in list_of_documents:\n",
    "        doc.page_content = doc.page_content.replace('\\t', ' ')  # Replace tabs with spaces\n",
    "    return list_of_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1d21982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF documents\n",
    "loader = PyPDFLoader(path)\n",
    "documents = loader.load()\n",
    "\n",
    "# Split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400, chunk_overlap=50, length_function=len\n",
    ")\n",
    "texts = text_splitter.split_documents(documents)\n",
    "cleaned_texts = replace_t_with_space(texts)\n",
    "\n",
    "# Create embeddings and vector store\n",
    "base_embeddings = CohereEmbeddings(\n",
    "    model=\"embed-english-light-v3.0\"\n",
    ")\n",
    "vectorstore = FAISS.from_documents(cleaned_texts, base_embeddings)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06703e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    max_output_tokens=3000,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm, retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efbf9807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_feedback(query, response, relevance, quality, comments=\"\"):\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"response\": response,\n",
    "        \"relevance\": int(relevance),\n",
    "        \"quality\": int(quality),\n",
    "        \"comments\": comments\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ca70249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_feedback(feedback):\n",
    "    with open(\"data/feedback_data.json\", \"a\") as f:\n",
    "        json.dump(feedback, f)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efcc7f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_feedback_data():\n",
    "    feedback_data = []\n",
    "    try:\n",
    "        with open(\"data/feedback_data.json\", \"r\") as f:\n",
    "            for line in f:\n",
    "                feedback_data.append(json.loads(line.strip()))\n",
    "    except FileNotFoundError:\n",
    "        print(\"No feedback data file found. Starting with empty feedback.\")\n",
    "    return feedback_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f28480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Response(BaseModel):\n",
    "    answer: str = Field(..., title=\"The answer to the question. The options can be only 'Yes' or 'No'\")\n",
    "\n",
    "def adjust_relevance_scores(query: str, docs: List[Any], feedback_data: List[Dict[str, Any]]) -> List[Any]:\n",
    "    # Create a prompt template for relevance checking\n",
    "    relevance_prompt = PromptTemplate(\n",
    "        input_variables=[\"query\", \"feedback_query\", \"doc_content\", \"feedback_response\"],\n",
    "        template=\"\"\"\n",
    "        Determine if the following feedback response is relevant to the current query and document content.\n",
    "        You are also provided with the Feedback original query that was used to generate the feedback response.\n",
    "        Current query: {query}\n",
    "        Feedback query: {feedback_query}\n",
    "        Document content: {doc_content}\n",
    "        Feedback response: {feedback_response}\n",
    "        \n",
    "        Is this feedback relevant? Respond with only 'Yes' or 'No'.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Create an LLMChain for relevance checking\n",
    "    relevance_chain = relevance_prompt | llm.with_structured_output(Response)\n",
    "\n",
    "    for i, doc in enumerate(docs):\n",
    "        if 'relevance_score' not in doc.metadata:\n",
    "            doc.metadata['relevance_score'] = 1.0 - (i * 0.1)\n",
    "        relevant_feedback = []\n",
    "        \n",
    "        for feedback in feedback_data:\n",
    "            # Use LLM to check relevance\n",
    "            input_data = {\n",
    "                \"query\": query,\n",
    "                \"feedback_query\": feedback['query'],\n",
    "                \"doc_content\": doc.page_content[:1000],\n",
    "                \"feedback_response\": feedback['response']\n",
    "            }\n",
    "            result = relevance_chain.invoke(input_data).answer\n",
    "            \n",
    "            if result == 'yes':\n",
    "                relevant_feedback.append(feedback)\n",
    "        \n",
    "        # Adjust the relevance score based on feedback\n",
    "        if relevant_feedback:\n",
    "            avg_relevance = sum(f['relevance'] for f in relevant_feedback) / len(relevant_feedback)\n",
    "            doc.metadata['relevance_score'] *= (avg_relevance / 3)  # Assuming a 1-5 scale, 3 is neutral\n",
    "    \n",
    "    # Re-rank documents based on adjusted scores\n",
    "    return sorted(docs, key=lambda x: x.metadata['relevance_score'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82116de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_from_string(content, chunk_size=400, chunk_overlap=50):\n",
    "    if not isinstance(content, str) or not content.strip():\n",
    "        raise ValueError(\"Content must be a non-empty string.\")\n",
    "\n",
    "    if not isinstance(chunk_size, int) or chunk_size <= 0:\n",
    "        raise ValueError(\"chunk_size must be a positive integer.\")\n",
    "\n",
    "    if not isinstance(chunk_overlap, int) or chunk_overlap < 0:\n",
    "        raise ValueError(\"chunk_overlap must be a non-negative integer.\")\n",
    "\n",
    "    try:\n",
    "        # Split the content into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            length_function=len,\n",
    "            is_separator_regex=False,\n",
    "        )\n",
    "        chunks = text_splitter.create_documents([content])\n",
    "\n",
    "        # Assign metadata to each chunk\n",
    "        for chunk in chunks:\n",
    "            chunk.metadata['relevance_score'] = 1.0\n",
    "\n",
    "        # Generate embeddings and create the vector store\n",
    "        embeddings = CohereEmbeddings(\n",
    "            model=\"embed-english-light-v3.0\"\n",
    "        )\n",
    "        vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"An error occurred during the encoding process: {str(e)}\")\n",
    "\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9a0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_index(feedback_data: List[Dict[str, Any]], texts: List[str]) -> Any:\n",
    "    # Filter high-quality responses\n",
    "    good_responses = [f for f in feedback_data if f['relevance'] >= 4 and f['quality'] >= 4]\n",
    "    \n",
    "    # Extract queries and responses, and create new documents\n",
    "    additional_texts = []\n",
    "    for f in good_responses:\n",
    "        combined_text = f['query'] + \" \" + f['response']\n",
    "        additional_texts.append(combined_text)\n",
    "\n",
    "    # make the list a string\n",
    "    additional_texts = \" \".join(additional_texts)\n",
    "    \n",
    "    # Create a new index with original and high-quality texts\n",
    "    all_texts = texts + additional_texts\n",
    "    new_vectorstore = encode_from_string(all_texts)\n",
    "    \n",
    "    return new_vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ebfa1745",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the greenhouse effect?\"\n",
    "\n",
    "# Get response from RAG system\n",
    "response = qa_chain.invoke(query)[\"result\"]\n",
    "\n",
    "relevance = 5\n",
    "quality = 5\n",
    "\n",
    "# Collect feedback\n",
    "feedback = get_user_feedback(query, response, relevance, quality)\n",
    "\n",
    "# Store feedback\n",
    "store_feedback(feedback)\n",
    "\n",
    "# Adjust relevance scores for future retrievals\n",
    "docs = retriever.invoke(query)\n",
    "adjusted_docs = adjust_relevance_scores(query, docs, load_feedback_data())\n",
    "\n",
    "# Update the retriever with adjusted docs\n",
    "retriever.search_kwargs['k'] = len(adjusted_docs)\n",
    "retriever.search_kwargs['docs'] = adjusted_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a218791a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greenhouse Gases \n",
      "The primary cause of recent climate change is the increase in greenhouse gases in the \n",
      "atmosphere. Greenhouse gases, such as carbon dioxide (CO2), methane (CH4), and nitrous \n",
      "oxide (N2O), trap heat from the sun, creating a \"greenhouse effect.\" This effect is essential \n",
      "for life on Earth, as it keeps the planet warm enough to support life. However, human\n",
      "---------------------\n",
      "greenhouse effect. \n",
      "Tropical Deforestation \n",
      "Tropical rainforests are particularly important for carbon storage. Deforestation in the \n",
      "Amazon, Congo Basin, and Southeast Asia has significant impacts on global carbon cycles \n",
      "and biodiversity. These regions are often cleared for agriculture, logging, and mining, leading \n",
      "to habitat loss and species extinction. \n",
      "Boreal Forests\n",
      "---------------------\n",
      "development of eco-friendly fertilizers and farming techniques is essential for reducing the \n",
      "agricultural sector's carbon footprint. \n",
      "Chapter 3: Effects of Climate Change \n",
      "The effects of climate change are already being felt around the world and are projected to \n",
      "intensify in the coming decades. These effects include: \n",
      "Rising Temperatures\n",
      "---------------------\n",
      "health concerns. \n",
      "Deforestation \n",
      "Forests act as carbon sinks, absorbing CO2 from the atmosphere. When trees are cut down \n",
      "for timber or to clear land for agriculture, this stored carbon is released back into the \n",
      "atmosphere. Deforestation reduces the number of trees that can absorb CO2, exacerbating the \n",
      "greenhouse effect. \n",
      "Tropical Deforestation\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(adjusted_docs)):\n",
    "    print(adjusted_docs[i].page_content)\n",
    "    print('---------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6aeb9a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "\n",
    "def read_pdf_to_string(path):\n",
    "    # Open the PDF document located at the specified path\n",
    "    doc = fitz.open(path)\n",
    "    content = \"\"\n",
    "    # Iterate over each page in the document\n",
    "    for page_num in range(len(doc)):\n",
    "        # Get the current page\n",
    "        page = doc[page_num]\n",
    "        # Extract the text content from the current page and append it to the content string\n",
    "        content += page.get_text()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a2dfc1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Periodically (e.g., daily or weekly), fine-tune the index\n",
    "content = read_pdf_to_string(path)\n",
    "new_vectorstore = fine_tune_index(load_feedback_data(), content)\n",
    "retriever = new_vectorstore.as_retriever()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
