{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ffe91938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_cohere import ChatCohere, CohereEmbeddings\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c139720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "data = 'data/attention_is_all_you_need.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9bad9a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with fitz.open(data) as pdf_file:\n",
    "    # Create a directory to store the images\n",
    "    if not os.path.exists(\"extracted_images\"):\n",
    "        os.makedirs(\"extracted_images\")\n",
    "\n",
    "    # Loop through every page in the PDF\n",
    "    for page_number in range(len(pdf_file)):\n",
    "        page = pdf_file[page_number]\n",
    "        \n",
    "        # Get the text on page\n",
    "        text = page.get_text().strip()\n",
    "        text_data.append({\"response\": text, \"name\": page_number+1})\n",
    "        # Get the list of images on the page\n",
    "        images = page.get_images(full=True)\n",
    "\n",
    "        # Loop through all images found on the page\n",
    "        for image_index, img in enumerate(images, start=0):\n",
    "            xref = img[0]  # Get the XREF of the image\n",
    "            base_image = pdf_file.extract_image(xref)  # Extract the image\n",
    "            image_bytes = base_image[\"image\"]  # Get the image bytes\n",
    "            image_ext = base_image[\"ext\"]  # Get the image extension\n",
    "            \n",
    "            # Load the image using PIL and save it\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "            image.save(f\"extracted_images/image_{page_number+1}_{image_index+1}.{image_ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "773d505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f3788ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mimetypes\n",
    "import base64\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b3ef2e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_base64_uri(file_path: str) -> str:\n",
    "    mime_type, _ = mimetypes.guess_type(file_path)\n",
    "    if mime_type is None:\n",
    "        raise ValueError(f\"Unable to determine file type: {file_path}\")\n",
    "\n",
    "    with open(file_path, \"rb\") as image_file:\n",
    "        binary_data = image_file.read()\n",
    "\n",
    "    base64_encoded_data = base64.b64encode(binary_data).decode('utf-8')\n",
    "\n",
    "    return f\"data:{mime_type};base64,{base64_encoded_data}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "401b22c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = \"You are an assistant tasked with summarizing tables, images and text for retrieval. \\\n",
    "    These summaries will be embedded and used to retrieve the raw text or table elements \\\n",
    "    Give a concise summary of the table or text that is well optimized for retrieval. Table or text or image:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b241993",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = []\n",
    "for img in os.listdir(\"extracted_images\"):\n",
    "    image_uri = image_to_base64_uri(f\"extracted_images/{img}\")\n",
    "\n",
    "    message = HumanMessage(\n",
    "        content=[\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": prompt_text,\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": image_uri},\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "    chain = llm | StrOutputParser()\n",
    "    response = chain.invoke([message])\n",
    "    img_data.append({\"response\": response, \"name\": img})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "288f9f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': \"This image illustrates the Transformer neural network architecture, featuring an encoder-decoder structure. The encoder processes input embeddings combined with positional encodings through N identical layers, each containing a Multi-Head Attention block and a Feed Forward block, both followed by Add & Norm. The decoder, also with N identical layers, takes shifted output embeddings and positional encodings, utilizing a Masked Multi-Head Attention block, a Multi-Head Attention block, and a Feed Forward block, all followed by Add & Norm. The decoder's final output passes through a Linear layer and Softmax to produce output probabilities.\",\n",
       " 'name': 'image_3_1.png'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7217b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set embeddings\n",
    "embedding_model = CohereEmbeddings(model=\"embed-english-light-v3.0\")\n",
    "\n",
    "# Load the document\n",
    "docs_list = [Document(page_content=text['response'], metadata={\"name\": text['name']}) for text in text_data]\n",
    "img_list = [Document(page_content=img['response'], metadata={\"name\": img['name']}) for img in img_data]\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=400, chunk_overlap=50\n",
    ")\n",
    "\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "img_splits = text_splitter.split_documents(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ec686ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to vectorstore\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits + img_splits, # adding the both text and image splits\n",
    "    collection_name=\"multi_model_rag\",\n",
    "    embedding=embedding_model,\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={'k': 1}, # number of documents to retrieve\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f4418ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the BLEU score of the Transformer (base model)?\"\n",
    "docs = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "22c32f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Transformer (base model) achieved a BLEU score of 27.3 on the English-to-German (EN-DE) newstest2014 test. For the English-to-French (EN-FR) newstest2014 test, its BLEU score was 38.1.\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "system = \"\"\"You are an assistant for question-answering tasks. Answer the question based upon your knowledge. \n",
    "Use three-to-five sentences maximum and keep the answer concise.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved documents: \\n\\n <docs>{documents}</docs> \\n\\n User question: <question>{question}</question>\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "generation = rag_chain.invoke({\"documents\":docs[0].page_content, \"question\": query})\n",
    "print(generation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
