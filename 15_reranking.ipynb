{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8df805d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minhq\\miniconda3\\envs\\rag\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain.docstore.document import Document\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from sentence_transformers import CrossEncoder\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain import PromptTemplate\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"Gemini API Key not found. Please set it in the .env file.\")\n",
    "\n",
    "base_embeddings = CohereEmbeddings(\n",
    "    model=\"embed-english-light-v3.0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f507df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_pdf(path, chunk_size=1000, chunk_overlap=200):\n",
    "    # Load PDF documents\n",
    "    loader = PyPDFLoader(path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Split documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len\n",
    "    )\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    for doc in texts:\n",
    "        doc.page_content = doc.page_content.replace('\\t', ' ')  # Replace tabs with spaces\n",
    "\n",
    "    # Create embeddings and vector store\n",
    "    vectorstore = FAISS.from_documents(texts, base_embeddings)\n",
    "\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7fc460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/Understanding_Climate_Change.pdf\"\n",
    "vectorstore = encode_pdf(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67909c6",
   "metadata": {},
   "source": [
    "## Method 1: Use LLM to rerank documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00a27bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingScore(BaseModel):\n",
    "    relevance_score: float = Field(..., description=\"The relevance score of a document to a query.\")\n",
    "\n",
    "def rerank_documents(query: str, docs: List[Document], top_n: int = 3) -> List[Document]:\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"query\", \"doc\"],\n",
    "        template=\"\"\"On a scale of 1-10, rate the relevance of the following document to the query. Consider the specific context and intent of the query, not just keyword matches.\n",
    "        Query: {query}\n",
    "        Document: {doc}\n",
    "        Relevance Score:\"\"\"\n",
    "    )\n",
    "    \n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        temperature=0,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "        # other params...\n",
    "    )\n",
    "    llm_chain = prompt_template | llm.with_structured_output(RatingScore)\n",
    "    \n",
    "    scored_docs = []\n",
    "    for doc in docs:\n",
    "        input_data = {\"query\": query, \"doc\": doc.page_content}\n",
    "        score = llm_chain.invoke(input_data).relevance_score\n",
    "        try:\n",
    "            score = float(score)\n",
    "        except ValueError:\n",
    "            score = 0  # Default score if parsing fails\n",
    "        scored_docs.append((doc, score))\n",
    "        time.sleep(10)  # To avoid rate limiting, you should adjust this based on your API limits\n",
    "    \n",
    "    reranked_docs = sorted(scored_docs, key=lambda x: x[1], reverse=True)\n",
    "    return [doc for doc, _ in reranked_docs[:top_n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0b34056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top initial documents:\n",
      "\n",
      "Document 1:\n",
      "Climate change is altering terrestrial ecosystems by shifting habitat ranges, changing species \n",
      "distributions, and impacting ecosystem functions. Forests, grasslands, and deserts are \n",
      "experiencing shi...\n",
      "\n",
      "Document 2:\n",
      "development of eco-friendly fertilizers and farming techniques is essential for reducing the \n",
      "agricultural sector's carbon footprint. \n",
      "Chapter 3: Effects of Climate Change \n",
      "The effects of climate chan...\n",
      "\n",
      "Document 3:\n",
      "goals. Policies should promote synergies between biodiversity conservation and climate \n",
      "action. \n",
      "Chapter 10: Climate Change and Human Health \n",
      "Health Impacts \n",
      "Heat-Related Illnesses \n",
      "Rising temperature...\n",
      "Query: What are the impacts of climate change on biodiversity?\n",
      "\n",
      "Top reranked documents:\n",
      "\n",
      "Document 1:\n",
      "Climate change is altering terrestrial ecosystems by shifting habitat ranges, changing species \n",
      "distributions, and impacting ecosystem functions. Forests, grasslands, and deserts are \n",
      "experiencing shi...\n",
      "\n",
      "Document 2:\n",
      "cultural perceptions. \n",
      "Youth Engagement \n",
      "Youth are vital stakeholders in climate action. Empowering young people through education, \n",
      "activism, and leadership opportunities can drive transformative cha...\n",
      "\n",
      "Document 3:\n",
      "Tropical rainforests are particularly important for carbon storage. Deforestation in the \n",
      "Amazon, Congo Basin, and Southeast Asia has significant impacts on global carbon cycles \n",
      "and biodiversity. The...\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the impacts of climate change on biodiversity?\"\n",
    "initial_docs = vectorstore.similarity_search(query, k=15)\n",
    "reranked_docs = rerank_documents(query, initial_docs)\n",
    "\n",
    "# print first 3 initial documents\n",
    "print(\"Top initial documents:\")\n",
    "for i, doc in enumerate(initial_docs[:3]):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"Top reranked documents:\")\n",
    "for i, doc in enumerate(reranked_docs[:3]):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03a16e7",
   "metadata": {},
   "source": [
    "## Why should we use reranking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7296efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minhq\\AppData\\Local\\Temp\\ipykernel_2344\\1154227627.py:1: DeprecationWarning: Retrievers must implement abstract `_get_relevant_documents` method instead of `get_relevant_documents`\n",
      "  class CustomRetriever(BaseRetriever, BaseModel):\n"
     ]
    }
   ],
   "source": [
    "class CustomRetriever(BaseRetriever, BaseModel):\n",
    "    \n",
    "    vectorstore: Any = Field(description=\"Vector store for initial retrieval\")\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def get_relevant_documents(self, query: str, num_docs=2) -> List[Document]:\n",
    "        initial_docs = self.vectorstore.similarity_search(query, k=30)\n",
    "        return rerank_documents(query, initial_docs, top_n=num_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "114dc7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Retrieval Techniques\n",
      "==================================\n",
      "Query: what is the capital of france?\n",
      "\n",
      "Baseline Retrieval Result:\n",
      "\n",
      "Document 1:\n",
      "The capital of France is great.\n",
      "\n",
      "Document 2:\n",
      "The capital of France is beautiful.\n",
      "\n",
      "Advanced Retrieval Result:\n",
      "\n",
      "Document 1:\n",
      "I really enjoyed my trip to Paris, France. The city is beautiful and the food is delicious. I would love to visit again. Such a great capital city.\n",
      "\n",
      "Document 2:\n",
      "The capital of France is huge.\n"
     ]
    }
   ],
   "source": [
    "chunks = [\n",
    "    \"The capital of France is great.\",\n",
    "    \"The capital of France is huge.\",\n",
    "    \"The capital of France is beautiful.\",\n",
    "    \"\"\"Have you ever visited Paris? It is a beautiful city where you can eat delicious food and see the Eiffel Tower. \n",
    "    I really enjoyed all the cities in france, but its capital with the Eiffel Tower is my favorite city.\"\"\", \n",
    "    \"I really enjoyed my trip to Paris, France. The city is beautiful and the food is delicious. I would love to visit again. Such a great capital city.\"\n",
    "]\n",
    "docs = [Document(page_content=sentence) for sentence in chunks]\n",
    "\n",
    "\n",
    "def compare_rag_techniques(query: str, docs: List[Document] = docs) -> None:\n",
    "    vectorstore = FAISS.from_documents(docs, base_embeddings)\n",
    "\n",
    "    print(\"Comparison of Retrieval Techniques\")\n",
    "    print(\"==================================\")\n",
    "    print(f\"Query: {query}\\n\")\n",
    "    \n",
    "    print(\"Baseline Retrieval Result:\")\n",
    "    baseline_docs = vectorstore.similarity_search(query, k=2)\n",
    "    for i, doc in enumerate(baseline_docs):\n",
    "        print(f\"\\nDocument {i+1}:\")\n",
    "        print(doc.page_content)\n",
    "\n",
    "    print(\"\\nAdvanced Retrieval Result:\")\n",
    "    custom_retriever = CustomRetriever(vectorstore=vectorstore)\n",
    "    advanced_docs = custom_retriever.get_relevant_documents(query)\n",
    "    for i, doc in enumerate(advanced_docs):\n",
    "        print(f\"\\nDocument {i+1}:\")\n",
    "        print(doc.page_content)\n",
    "\n",
    "\n",
    "query = \"what is the capital of france?\"\n",
    "compare_rag_techniques(query, docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6685fc7",
   "metadata": {},
   "source": [
    "## Method 2: Cross Encoder models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "845fab91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minhq\\AppData\\Local\\Temp\\ipykernel_2344\\2986707392.py:3: DeprecationWarning: Retrievers must implement abstract `_get_relevant_documents` method instead of `get_relevant_documents`\n",
      "  class CrossEncoderRetriever(BaseRetriever, BaseModel):\n",
      "C:\\Users\\minhq\\AppData\\Local\\Temp\\ipykernel_2344\\2986707392.py:3: DeprecationWarning: Retrievers must implement abstract `_aget_relevant_documents` method instead of `aget_relevant_documents`\n",
      "  class CrossEncoderRetriever(BaseRetriever, BaseModel):\n"
     ]
    }
   ],
   "source": [
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "\n",
    "class CrossEncoderRetriever(BaseRetriever, BaseModel):\n",
    "    vectorstore: Any = Field(description=\"Vector store for initial retrieval\")\n",
    "    cross_encoder: Any = Field(description=\"Cross-encoder model for reranking\")\n",
    "    k: int = Field(default=5, description=\"Number of documents to retrieve initially\")\n",
    "    rerank_top_k: int = Field(default=3, description=\"Number of documents to return after reranking\")\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        # Initial retrieval\n",
    "        initial_docs = self.vectorstore.similarity_search(query, k=self.k)\n",
    "        \n",
    "        # Prepare pairs for cross-encoder\n",
    "        pairs = [[query, doc.page_content] for doc in initial_docs]\n",
    "        \n",
    "        # Get cross-encoder scores\n",
    "        scores = self.cross_encoder.predict(pairs)\n",
    "        \n",
    "        # Sort documents by score\n",
    "        scored_docs = sorted(zip(initial_docs, scores), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Return top reranked documents\n",
    "        return [doc for doc, _ in scored_docs[:self.rerank_top_k]]\n",
    "\n",
    "    async def aget_relevant_documents(self, query: str) -> List[Document]:\n",
    "        raise NotImplementedError(\"Async retrieval not implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0007f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minhq\\AppData\\Local\\Temp\\ipykernel_2344\\736525030.py:28: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: What are the impacts of climate change on biodiversity?\n",
      "Answer: Climate change impacts biodiversity in several ways across different ecosystems:\n",
      "\n",
      "**Terrestrial Ecosystems:**\n",
      "*   **Shifting habitat ranges:** Animals and plants are forced to move to new areas.\n",
      "*   **Changing species distributions:** The geographical spread of species is altered.\n",
      "*   **Impacts on ecosystem functions:** The natural processes within ecosystems are disrupted.\n",
      "*   **Shifts in plant and animal species composition:** The types of species found in forests, grasslands, and deserts are changing.\n",
      "*   **Loss of biodiversity:** The variety of life forms is reduced.\n",
      "*   **Disruption of ecological balance:** The natural equilibrium of ecosystems is disturbed.\n",
      "\n",
      "**Marine Ecosystems:**\n",
      "*   **Rising sea temperatures:** Warmer waters stress marine life.\n",
      "*   **Ocean acidification:** Increased acidity harms organisms, especially those with shells or skeletons like coral reefs.\n",
      "*   **Changing currents:** Ocean currents, which transport nutrients and larvae, are altered.\n",
      "*   **Affects marine biodiversity:** Impacts range from coral reefs to deep-sea habitats.\n",
      "*   **Species migration:** Marine species move to find more suitable conditions.\n",
      "*   **Changes in reproductive cycles:** Breeding patterns are disrupted.\n",
      "*   **Disruption of marine food webs and fisheries:** The interconnectedness of marine life and human food sources are affected.\n",
      "\n",
      "Relevant source documents:\n",
      "\n",
      "Document 1:\n",
      "Climate change is altering terrestrial ecosystems by shifting habitat ranges, changing species \n",
      "distributions, and impacting ecosystem functions. Forests, grasslands, and deserts are \n",
      "experiencing shi...\n",
      "\n",
      "Document 2:\n",
      "protection, and habitat creation. \n",
      "Climate-Resilient Conservation \n",
      "Conservation strategies must account for climate change impacts to be effective. This \n",
      "includes identifying climate refugia, areas le...\n",
      "\n",
      "Document 3:\n",
      "goals. Policies should promote synergies between biodiversity conservation and climate \n",
      "action. \n",
      "Chapter 10: Climate Change and Human Health \n",
      "Health Impacts \n",
      "Heat-Related Illnesses \n",
      "Rising temperature...\n",
      "\n",
      "Document 4:\n",
      "cultural perceptions. \n",
      "Youth Engagement \n",
      "Youth are vital stakeholders in climate action. Empowering young people through education, \n",
      "activism, and leadership opportunities can drive transformative cha...\n",
      "\n",
      "Document 5:\n",
      "Tropical rainforests are particularly important for carbon storage. Deforestation in the \n",
      "Amazon, Congo Basin, and Southeast Asia has significant impacts on global carbon cycles \n",
      "and biodiversity. The...\n"
     ]
    }
   ],
   "source": [
    "# Create the cross-encoder retriever\n",
    "cross_encoder_retriever = CrossEncoderRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    cross_encoder=cross_encoder,\n",
    "    k=10,  # Retrieve 10 documents initially\n",
    "    rerank_top_k=5  # Return top 5 after reranking\n",
    ")\n",
    "\n",
    "# Set up the LLM\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "# Create the RetrievalQA chain with the cross-encoder retriever\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=cross_encoder_retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# Example query\n",
    "query = \"What are the impacts of climate change on biodiversity?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(f\"\\nQuestion: {query}\")\n",
    "print(f\"Answer: {result['result']}\")\n",
    "print(\"\\nRelevant source documents:\")\n",
    "for i, doc in enumerate(result[\"source_documents\"]):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
