{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf907e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9848596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6637dfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'RAG_TECHNIQUES/data/Understanding_Climate_Change.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de0513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_document(file_path):\n",
    "    \"\"\"\n",
    "    Load a PDF and return all pages as documents\n",
    "    \"\"\"\n",
    "    try:\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        documents = loader.load()\n",
    "        print(f\"Loaded {len(documents)} pages from PDF\")\n",
    "        return documents\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading PDF: {e}\")\n",
    "        return []\n",
    "    \n",
    "def create_document_chunks(documents, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Split documents into overlapping chunks for processing\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len  # Use character count for splitting\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    # Clean up the text\n",
    "    for chunk in chunks:\n",
    "        chunk.page_content = chunk.page_content.replace('\\t', ' ')\n",
    "        chunk.page_content = chunk.page_content.replace('\\n\\n\\n', '\\n\\n')\n",
    "        chunk.page_content = chunk.page_content.strip()\n",
    "    print(f\"Created {len(chunks)} chunks\")\n",
    "    print(f\"Average chunk size: {sum(len(chunk.page_content) for chunk in chunks) // len(chunks)} characters\")\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77f1c22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 33 pages from PDF\n",
      "Created 97 chunks\n",
      "Average chunk size: 799 characters\n"
     ]
    }
   ],
   "source": [
    "# Load and chunk the document\n",
    "documents = load_pdf_document(path)\n",
    "if documents:\n",
    "    chunks = create_document_chunks(documents, chunk_size=1000, chunk_overlap=100)\n",
    "else:\n",
    "    print(\"Failed to load document. Please check your PDF path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "def21d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Understanding Climate Change \n",
      "Chapter 1: Introduction to Climate Change \n",
      "Climate change refers to significant, long-term changes in the global climate. The term \n",
      "\"global climate\" encompasses the planet's overall weather patterns, including temperature, \n",
      "precipitation, and wind patterns, over an extended period. Over the past century, human \n",
      "activities, particularly the burning of fossil fuels and deforestation, have significantly \n",
      "contributed to climate change. \n",
      "Historical Context \n",
      "The Earth's climate has changed throughout history. Over the past 650,000 years, there have \n",
      "been seven cycles of glacial advance and retreat, with the abrupt end of the last ice age about \n",
      "11,700 years ago marking the beginning of the modern climate era and human civilization. \n",
      "Most of these climate changes are attributed to very small variations in Earth's orbit that \n",
      "change the amount of solar energy our planet receives. During the Holocene epoch, which\n",
      "----------------------------\n",
      "change the amount of solar energy our planet receives. During the Holocene epoch, which \n",
      "began at the end of the last ice age, human societies flourished, but the industrial era has seen \n",
      "unprecedented changes. \n",
      "Modern Observations \n",
      "Modern scientific observations indicate a rapid increase in global temperatures, sea levels, \n",
      "and extreme weather events. The Intergovernmental Panel on Climate Change (IPCC) has \n",
      "documented these changes extensively. Ice core samples, tree rings, and ocean sediments \n",
      "provide a historical record that scientists use to understand past climate conditions and \n",
      "predict future trends. The evidence overwhelmingly shows that recent changes are primarily \n",
      "driven by human activities, particularly the emission of greenhouse gases. \n",
      "Chapter 2: Causes of Climate Change \n",
      "Greenhouse Gases \n",
      "The primary cause of recent climate change is the increase in greenhouse gases in the \n",
      "atmosphere. Greenhouse gases, such as carbon dioxide (CO2), methane (CH4), and nitrous\n",
      "----------------------------\n",
      "atmosphere. Greenhouse gases, such as carbon dioxide (CO2), methane (CH4), and nitrous \n",
      "oxide (N2O), trap heat from the sun, creating a \"greenhouse effect.\" This effect is essential \n",
      "for life on Earth, as it keeps the planet warm enough to support life. However, human \n",
      "activities have intensified this natural process, leading to a warmer climate. \n",
      "Fossil Fuels \n",
      "Burning fossil fuels for energy releases large amounts of CO2. This includes coal, oil, and \n",
      "natural gas used for electricity, heating, and transportation. The industrial revolution marked \n",
      "the beginning of a significant increase in fossil fuel consumption, which continues to rise \n",
      "today. \n",
      "Coal\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks[:3]:\n",
    "    print(chunk.page_content)\n",
    "    print('----------------------------')\n",
    "    # response_object = question_chain.invoke({\"chunk_text\": chunk.page_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9700ed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HypotheticalQuestions(BaseModel):\n",
    "    \"\"\"A list of hypothetical questions that a user might ask about a text chunk.\"\"\"\n",
    "    questions: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"A list of 3-5 varied, natural, and conversational questions based on the text.\"\n",
    "    )\n",
    "\n",
    "# Create the parser from our Pydantic model\n",
    "pydantic_parser = PydanticOutputParser(pydantic_object=HypotheticalQuestions)\n",
    "\n",
    "# Create a new, more robust prompt that includes the format instructions\n",
    "question_prompt_with_schema = PromptTemplate(\n",
    "    template=\"\"\"You are an expert at generating questions. Your task is to analyze the following text and generate 3-5 essential questions that a user might ask about this content.\n",
    "\n",
    "Requirements:\n",
    "- Each question should capture a key concept or fact from the text.\n",
    "- Questions should be varied (factual, conceptual, comparative).\n",
    "- Questions should be natural and conversational.\n",
    "\n",
    "Text:\n",
    "{chunk_text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\",\n",
    "    input_variables=[\"chunk_text\"],\n",
    "    partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "question_chain = question_prompt_with_schema | llm | pydantic_parser\n",
    "\n",
    "response_object = question_chain.invoke({\"chunk_text\": chunk_text})\n",
    "# Not enough API calls made to generate a response, skipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5819cb13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
